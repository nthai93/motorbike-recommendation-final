# ============================================================
# üìò preprocess.py ‚Äì Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu & vƒÉn b·∫£n cho h·ªá th·ªëng
# ============================================================

import pandas as pd
import numpy as np
import os, re, unicodedata
from underthesea import word_tokenize

# ============================================================
# 1Ô∏è‚É£ H√ÄM TI·ªÜN √çCH
# ============================================================

def remove_accents(text):
    """B·ªè d·∫•u ti·∫øng Vi·ªát"""
    if pd.isnull(text):
        return ""
    text = unicodedata.normalize("NFD", text)
    text = text.encode("ascii", "ignore").decode("utf-8")
    return str(text)

def clean_text_light(text):
    """L√†m s·∫°ch nh·∫π (cho Word2Vec)"""
    if pd.isnull(text): return ""
    text = str(text).lower()
    text = word_tokenize(text, format="text")
    text = re.sub(r"[^a-zA-Z0-9√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá"
                  r"√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±"
                  r"√Ω·ª≥·ª∑·ªπ·ªµƒë\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def clean_text_full(text):
    """L√†m s·∫°ch m·∫°nh (cho TF-IDF)"""
    if pd.isnull(text): return ""
    text = str(text).lower()
    text = remove_accents(text)
    text = word_tokenize(text, format="text")
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


# ============================================================
# 2Ô∏è‚É£ LOAD & FEATURE ENGINEERING
# ============================================================

def load_data(path="data/data_motorbikes.xlsx"):
    print("üì• ƒêang ƒë·ªçc d·ªØ li·ªáu ƒë·∫ßu v√†o...")
    df = pd.read_excel(path)
    df = df.dropna(subset=["Ti√™u ƒë·ªÅ", "M√¥ t·∫£ chi ti·∫øt"])

    # üîë Gi·ªØ ID g·ªëc t·ª´ Excel ho·∫∑c t·∫°o m·ªõi n·∫øu ch∆∞a c√≥
    if "id" not in df.columns:
        df.insert(0, "id", range(1, len(df) + 1))
    else:
        df["id"] = pd.to_numeric(df["id"], errors="coerce").fillna(method="ffill").astype(int)

    print(f"‚úÖ ƒê·ªçc th√†nh c√¥ng {len(df)} d√≤ng t·ª´ {path}")
    return df


def feature_engineering(df):
    """T·∫°o feature k·ªπ thu·∫≠t ph·ª•c v·ª• clustering"""
    print("‚öôÔ∏è  ƒêang t·∫°o c√°c feature k·ªπ thu·∫≠t...")

    # 1Ô∏è‚É£ T√¨m c·ªôt c√≥ ch·ª©a 'nƒÉm' v√† √©p ki·ªÉu sang s·ªë
    year_cols = [c for c in df.columns if "nƒÉm" in c.lower()]
    if year_cols:
        year_col = year_cols[0]
        df[year_col] = pd.to_numeric(df[year_col], errors='coerce')
        df["Tuoi_xe"] = 2025 - df[year_col]
    else:
        df["Tuoi_xe"] = np.nan
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y c·ªôt nƒÉm s·∫£n xu·∫•t, g√°n NaN.")

    # 2Ô∏è‚É£ T√¨m c·ªôt ch·ª©a th√¥ng tin km
    km_cols = [c for c in df.columns if "km" in c.lower()]
    if km_cols:
        df["S·ªë_km_da_ƒëi"] = pd.to_numeric(df[km_cols[0]], errors='coerce')
    else:
        df["S·ªë_km_da_ƒëi"] = np.nan
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y c·ªôt s·ªë km, g√°n NaN.")

    # 3Ô∏è‚É£ T√¨m v√† x·ª≠ l√Ω c·ªôt gi√°
    if "Gi√°" in df.columns:
        df["Gi√°"] = (
            df["Gi√°"].astype(str)
            .str.replace("[^0-9]", "", regex=True)
            .replace("", np.nan)
            .astype(float) / 1_000_000
        )
        print("‚úÖ ƒê√£ x·ª≠ l√Ω c·ªôt 'Gi√°' th√†nh s·ªë (tri·ªáu ƒë·ªìng).")

    elif all(col in df.columns for col in ["Kho·∫£ng gi√° min", "Kho·∫£ng gi√° max"]):
        df["Gi√°"] = (
            df[["Kho·∫£ng gi√° min", "Kho·∫£ng gi√° max"]]
            .apply(lambda x: np.mean([
                float(re.sub('[^0-9.,]', '', str(v)).replace(',', '.'))
                for v in x if re.sub('[^0-9.,]', '', str(v)).strip() != ""
            ]), axis=1)
        )
        print("‚úÖ ƒê√£ t√≠nh 'Gi√°' trung b√¨nh t·ª´ kho·∫£ng gi√° min/max (tri·ªáu ƒë·ªìng).")

    else:
        df["Gi√°"] = np.nan
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y c·ªôt gi√°, g√°n NaN.")

    # 4Ô∏è‚É£ T√≠nh to√°n feature m·ªõi
    df["Km_moi_nam"] = df["S·ªë_km_da_ƒëi"] / (df["Tuoi_xe"] + 0.1)
    df["Tuoi_xe_x_Km"] = df["Tuoi_xe"] * df["S·ªë_km_da_ƒëi"]
    df["Log_Gia"] = np.log1p(df["Gi√°"])

    print("‚úÖ Ho√†n t·∫•t t·∫°o feature k·ªπ thu·∫≠t (Tuoi_xe, Km_moi_nam, Log_Gia...).")
    return df


# ============================================================
# 3Ô∏è‚É£ TEXT PIPELINE ‚Äì Chu·∫©n h√≥a m√¥ t·∫£ xe
# ============================================================

def text_processing(df, mode="light"):
    """Ti·ªÅn x·ª≠ l√Ω text cho TF-IDF / Word2Vec"""
    print("üßπ ƒêang x·ª≠ l√Ω vƒÉn b·∫£n m√¥ t·∫£...")

    func = clean_text_full if mode == "full" else clean_text_light
    text_cols = [
        "Ti√™u ƒë·ªÅ", "Th∆∞∆°ng hi·ªáu", "D√≤ng xe", "Lo·∫°i xe",
        "Dung t√≠ch xe", "M√¥ t·∫£ chi ti·∫øt"
    ]
    for col in text_cols:
        if col in df.columns:
            df[col] = df[col].apply(func)
        else:
            df[col] = ""

    df["full_description"] = df[text_cols].agg(" ".join, axis=1)
    print(f"‚úÖ Ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ({mode.upper()} mode).")
    return df


# ============================================================
# 4Ô∏è‚É£ PIPELINE T·ªîNG ‚Äì CHU·∫®N H√ìA & XU·∫§T FILE
# ============================================================

def preprocess_pipeline(mode="light"):
    """Pipeline ch√≠nh cho to√†n b·ªô ti·ªÅn x·ª≠ l√Ω"""
    print("üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU...\n")
    df = load_data()
    print("------------------------------------------------------")
    df = feature_engineering(df)
    print("------------------------------------------------------")
    df = text_processing(df, mode=mode)
    print("------------------------------------------------------")

    # S·∫Øp x·∫øp th·ª© t·ª± c·ªôt quan tr·ªçng (gi·ªØ ID g·ªëc)
    main_cols = [
        "id",
        "Th∆∞∆°ng hi·ªáu", "D√≤ng xe", "Lo·∫°i xe", "Dung t√≠ch xe",
        "Gi√°", "S·ªë_km_da_ƒëi", "Tuoi_xe", "Km_moi_nam",
        "Tuoi_xe_x_Km", "Log_Gia", "full_description"
    ]
    df = df[[c for c in main_cols if c in df.columns]]

    # Xu·∫•t file k·∫øt qu·∫£
    output_path = "data/motorbike_final_dataset_clean.csv"
    df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"üíæ ƒê√£ l∆∞u file: {output_path}")
    print("üéØ D·ªØ li·ªáu s·∫µn s√†ng cho Clustering & Recommendation.\n")
    print("=======================================================")
    print(df.head(3))
    print("=======================================================")
    return df


# ============================================================
# 5Ô∏è‚É£ CH·∫†Y TH·ª¨
# ============================================================

if __name__ == "__main__":
    df = preprocess_pipeline(mode="light")
    print("‚úÖ Quy tr√¨nh ti·ªÅn x·ª≠ l√Ω ho√†n t·∫•t th√†nh c√¥ng.")
